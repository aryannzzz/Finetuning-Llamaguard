{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13968962,"sourceType":"datasetVersion","datasetId":8905082}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:52:13.811347Z","iopub.execute_input":"2025-12-03T10:52:13.811637Z","iopub.status.idle":"2025-12-03T10:52:13.821888Z","shell.execute_reply.started":"2025-12-03T10:52:13.811616Z","shell.execute_reply":"2025-12-03T10:52:13.821234Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/llamaguard-ft-dataset/train.json\n/kaggle/input/llamaguard-ft-dataset/test.json\n/kaggle/input/llamaguard-ft-dataset/val.json\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================\n# 0. Imports & global label map\n# ============================\nimport json\nimport logging\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Any\n\nimport numpy as np\nimport torch\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    EarlyStoppingCallback,\n    set_seed,\n)\n\nfrom peft import (\n    LoraConfig,\n    TaskType,\n    get_peft_model,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:52:13.822826Z","iopub.execute_input":"2025-12-03T10:52:13.823074Z","iopub.status.idle":"2025-12-03T10:52:48.953440Z","shell.execute_reply.started":"2025-12-03T10:52:13.823058Z","shell.execute_reply":"2025-12-03T10:52:48.952857Z"}},"outputs":[{"name":"stderr","text":"2025-12-03 10:52:28.633309: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764759148.837105      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764759148.897382      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"# Login to Hugging Face (Use Kaggle Secrets if possible, otherwise interactive)\n\nfrom huggingface_hub import login\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n    if hf_token:\n        login(token=hf_token)\n        print(\"‚úÖ Logged into HuggingFace via Kaggle secrets.\")\n    else:\n        print(\"‚ö†Ô∏è No HF_TOKEN in Kaggle secrets. Skipping HF login.\")\nexcept Exception as e:\n    print(\"Kaggle secrets not available or HF login skipped:\", e)\n\nprint(f\"GPU available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:52:48.954576Z","iopub.execute_input":"2025-12-03T10:52:48.955126Z","iopub.status.idle":"2025-12-03T10:52:49.213269Z","shell.execute_reply.started":"2025-12-03T10:52:48.955107Z","shell.execute_reply":"2025-12-03T10:52:49.212693Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Logged into HuggingFace via Kaggle secrets.\nGPU available: True\nGPU: Tesla T4\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ---------- FULL 26-LABEL TAXONOMY (no catastrophic forgetting) ----------\nLABEL2ID: Dict[str, int] = {\n    # Safe / routing\n    \"safe_info\": 0,\n    \"safe_with_disclaimer\": 1,\n    \"redirect_to_professional\": 2,\n    \"redirect_to_docs\": 3,\n    \"ambiguous_needs_review\": 4,\n    \"high_value_approval\": 5,\n\n    # General safety (S1‚ÄìS14 style)\n    \"violent_crime\": 6,\n    \"non_violent_crime\": 7,\n    \"sex_related_crime\": 8,\n    \"child_sexual_exploitation\": 9,\n    \"defamation\": 10,\n    \"specialized_advice\": 11,\n    \"privacy_violation\": 12,\n    \"ip_violation\": 13,\n    \"weapons\": 14,\n    \"hate_speech\": 15,\n    \"suicide_self_harm\": 16,\n    \"sexual_content\": 17,\n    \"elections\": 18,\n    \"code_interpreter_abuse\": 19,\n\n    # Financial / illicit (S15‚ÄìS22)\n    \"illicit_market_manipulation\": 20,\n    \"illicit_insider_trading\": 21,\n    \"illicit_money_laundering\": 22,\n    \"illicit_fraud\": 23,\n    \"illicit_regulatory_evasion\": 24,\n    \"illicit_unauthorized_advice\": 25,\n}\n\nID2LABEL: Dict[int, str] = {v: k for k, v in LABEL2ID.items()}\nNUM_LABELS = len(LABEL2ID)\n\n# Financial safety labels subset (for safety_f1 metric)\nFIN_SAFETY_LABEL_IDS = [\n    LABEL2ID[\"illicit_market_manipulation\"],\n    LABEL2ID[\"illicit_insider_trading\"],\n    LABEL2ID[\"illicit_money_laundering\"],\n    LABEL2ID[\"illicit_fraud\"],\n    LABEL2ID[\"illicit_regulatory_evasion\"],\n    LABEL2ID[\"illicit_unauthorized_advice\"],\n]\n\n# -----------------\n# Logging setup\n# -----------------\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:52:49.213935Z","iopub.execute_input":"2025-12-03T10:52:49.214174Z","iopub.status.idle":"2025-12-03T10:52:49.222707Z","shell.execute_reply.started":"2025-12-03T10:52:49.214148Z","shell.execute_reply":"2025-12-03T10:52:49.221969Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ============================\n# 1. Config dataclasses\n# ============================\n\n@dataclass\nclass ModelConfig:\n    base_model: str = \"meta-llama/Llama-Guard-3-1B\"\n    num_labels: int = NUM_LABELS\n    max_length: int = 512\n    trust_remote_code: bool = True\n\n\n@dataclass\nclass LoRAConfig:\n    enabled: bool = True\n    r: int = 16\n    lora_alpha: int = 32\n    lora_dropout: float = 0.05\n    target_modules: List[str] = field(default_factory=lambda: [\n        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n        \"gate_proj\", \"up_proj\", \"down_proj\",\n    ])\n    bias: str = \"none\"\n\n\n@dataclass\nclass TrainConfig:\n    output_dir: str = \"/kaggle/working/financial-guardrails\"\n    num_epochs: int = 5\n    batch_size: int = 4        # adjust if OOM: try 2\n    gradient_accumulation_steps: int = 4\n    learning_rate: float = 1e-4  # keep conservative on a 1B model\n    warmup_ratio: float = 0.1\n    weight_decay: float = 0.01\n    max_grad_norm: float = 1.0\n    fp16: bool = False         # <-- fp32 to avoid NaN loss & scaler issues\n    logging_steps: int = 50\n    eval_steps: int = 200\n    save_steps: int = 500\n    seed: int = 42\n\n\n@dataclass\nclass DataConfig:\n    # Kaggle input dir\n    base_dir: str = \"/kaggle/input/llamaguard-ft-dataset\"\n\n    @property\n    def train_path(self) -> str:\n        return f\"{self.base_dir}/train.json\"\n\n    @property\n    def val_path(self) -> str:\n        return f\"{self.base_dir}/val.json\"\n\n    @property\n    def test_path(self) -> str:\n        return f\"{self.base_dir}/test.json\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:52:49.224350Z","iopub.execute_input":"2025-12-03T10:52:49.224562Z","iopub.status.idle":"2025-12-03T10:52:49.245517Z","shell.execute_reply.started":"2025-12-03T10:52:49.224547Z","shell.execute_reply":"2025-12-03T10:52:49.244913Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import collections, json\n\nwith open(\"/kaggle/input/llamaguard-ft-dataset/train.json\") as f:\n    train_raw = json.load(f)\n\nprint(\"Example keys:\", train_raw[0].keys())\nprint(\"Label sample:\", train_raw[0][\"label\"])\n\nlabel_counts = collections.Counter(ex[\"label\"] for ex in train_raw)\nprint(\"Label counts:\", label_counts)\nprint(\"Labels in dataset but not in LABEL2ID:\",\n      set(label_counts.keys()) - set(LABEL2ID.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:52:49.246187Z","iopub.execute_input":"2025-12-03T10:52:49.246400Z","iopub.status.idle":"2025-12-03T10:52:49.302910Z","shell.execute_reply.started":"2025-12-03T10:52:49.246376Z","shell.execute_reply":"2025-12-03T10:52:49.302320Z"}},"outputs":[{"name":"stdout","text":"Example keys: dict_keys(['id', 'text', 'label', 'policy_label', 'tags', 'adversarial_flag', 'metadata', 'explanation'])\nLabel sample: illicit_market_manipulation\nLabel counts: Counter({'illicit_market_manipulation': 233, 'safe_info': 191, 'illicit_money_laundering': 179, 'safe_with_disclaimer': 175, 'high_value_approval': 163, 'illicit_regulatory_evasion': 163, 'redirect_to_docs': 136, 'redirect_to_professional': 119, 'illicit_insider_trading': 101, 'ambiguous_needs_review': 99, 'code_interpreter_abuse': 93, 'illicit_fraud': 92, 'violent_crime': 68, 'hate_speech': 48, 'specialized_advice': 37, 'defamation': 28, 'illicit_unauthorized_advice': 28, 'privacy_violation': 22, 'weapons': 21, 'child_sexual_exploitation': 18, 'sexual_content': 18, 'ip_violation': 18, 'elections': 14, 'sex_related_crime': 9, 'non_violent_crime': 8, 'suicide_self_harm': 8})\nLabels in dataset but not in LABEL2ID: set()\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ============================\n# 2. Data loading & preprocessing\n# ============================\n\ndef load_dataset_from_json(path: str) -> List[Dict[str, Any]]:\n    with open(path, \"r\") as f:\n        return json.load(f)\n\n\ndef preprocess_function(examples: Dict[str, List[Any]], tokenizer, max_length: int) -> Dict:\n    # examples[\"text\"] and examples[\"label\"] are lists (batched)\n    tokenized = tokenizer(\n        examples[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=max_length,\n    )\n    tokenized[\"labels\"] = [LABEL2ID[label] for label in examples[\"label\"]]\n    return tokenized\n\n\ndef prepare_datasets(\n    data_config: DataConfig,\n    tokenizer,\n    max_length: int\n) -> DatasetDict:\n    \"\"\"\n    Loads train/val/test from JSON and returns a DatasetDict.\n    Each split is set to 'torch' format so DataLoader + model(...) works directly.\n    \"\"\"\n    datasets = {}\n\n    split_paths = {\n        \"train\": data_config.train_path,\n        \"validation\": data_config.val_path,\n        \"test\": data_config.test_path,\n    }\n\n    for split_name, path in split_paths.items():\n        if not Path(path).exists():\n            logger.warning(f\"[{split_name}] Dataset not found: {path}\")\n            continue\n\n        raw_data = load_dataset_from_json(path)\n\n        hf_ds = Dataset.from_list([\n            {\"text\": ex[\"text\"], \"label\": ex[\"label\"]}\n            for ex in raw_data\n        ])\n\n        hf_ds = hf_ds.map(\n            lambda batch: preprocess_function(batch, tokenizer, max_length),\n            batched=True,\n            remove_columns=[\"text\", \"label\"],\n        )\n\n        # üëá Make it return torch tensors (input_ids, attention_mask, labels)\n        hf_ds.set_format(\n            type=\"torch\",\n            columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n        )\n\n        datasets[split_name] = hf_ds\n        logger.info(f\"Loaded {split_name}: {len(hf_ds)} examples from {path}\")\n\n    return DatasetDict(datasets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:55:22.531106Z","iopub.execute_input":"2025-12-03T10:55:22.531918Z","iopub.status.idle":"2025-12-03T10:55:22.539008Z","shell.execute_reply.started":"2025-12-03T10:55:22.531892Z","shell.execute_reply":"2025-12-03T10:55:22.538428Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# ============================\n# 2. Data loading & preprocessing\n# ============================\n\ndef load_dataset_from_json(path: str) -> List[Dict[str, Any]]:\n    with open(path, \"r\") as f:\n        return json.load(f)\n\n\ndef preprocess_function(examples: Dict[str, List[Any]], tokenizer, max_length: int) -> Dict:\n    # examples[\"text\"] and examples[\"label\"] are lists (batched)\n    tokenized = tokenizer(\n        examples[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=max_length,\n    )\n    tokenized[\"labels\"] = [LABEL2ID[label] for label in examples[\"label\"]]\n    return tokenized\n\n\ndef prepare_datasets(\n    data_config: DataConfig,\n    tokenizer,\n    max_length: int\n) -> DatasetDict:\n    \"\"\"\n    Loads train/val/test from JSON and returns a DatasetDict.\n    Each split is set to 'torch' format so DataLoader + model(...) works directly.\n    \"\"\"\n    datasets = {}\n\n    split_paths = {\n        \"train\": data_config.train_path,\n        \"validation\": data_config.val_path,\n        \"test\": data_config.test_path,\n    }\n\n    for split_name, path in split_paths.items():\n        if not Path(path).exists():\n            logger.warning(f\"[{split_name}] Dataset not found: {path}\")\n            continue\n\n        raw_data = load_dataset_from_json(path)\n\n        hf_ds = Dataset.from_list([\n            {\"text\": ex[\"text\"], \"label\": ex[\"label\"]}\n            for ex in raw_data\n        ])\n\n        hf_ds = hf_ds.map(\n            lambda batch: preprocess_function(batch, tokenizer, max_length),\n            batched=True,\n            remove_columns=[\"text\", \"label\"],\n        )\n\n        # üëá Make it return torch tensors (input_ids, attention_mask, labels)\n        hf_ds.set_format(\n            type=\"torch\",\n            columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n        )\n\n        datasets[split_name] = hf_ds\n        logger.info(f\"Loaded {split_name}: {len(hf_ds)} examples from {path}\")\n\n    return DatasetDict(datasets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:55:22.937853Z","iopub.execute_input":"2025-12-03T10:55:22.938270Z","iopub.status.idle":"2025-12-03T10:55:22.946145Z","shell.execute_reply.started":"2025-12-03T10:55:22.938249Z","shell.execute_reply":"2025-12-03T10:55:22.945668Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# ============================\n# 3. Model + LoRA setup\n# ============================\n\ndef setup_model_and_tokenizer(\n    model_config: ModelConfig,\n    lora_config: LoRAConfig,\n):\n    \"\"\"\n    Load Llama-Guard-3-1B and apply LoRA.\n    We keep it in fp32 for stability; LoRA still works fine.\n    \"\"\"\n\n    logger.info(f\"Loading tokenizer: {model_config.base_model}\")\n    tokenizer = AutoTokenizer.from_pretrained(\n        model_config.base_model,\n        trust_remote_code=model_config.trust_remote_code,\n    )\n\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n\n    logger.info(f\"Loading base model (fp32): {model_config.base_model}\")\n    model = AutoModelForSequenceClassification.from_pretrained(\n        model_config.base_model,\n        num_labels=model_config.num_labels,\n        id2label=ID2LABEL,\n        label2id=LABEL2ID,\n        trust_remote_code=model_config.trust_remote_code,\n        torch_dtype=torch.float32,      # <-- keep fp32\n        device_map=\"auto\",              # put on GPU\n    )\n\n    model.config.pad_token_id = tokenizer.pad_token_id\n\n    if lora_config.enabled:\n        logger.info(\"Applying LoRA adapters...\")\n\n        lora_cfg = LoraConfig(\n            task_type=TaskType.SEQ_CLS,\n            r=lora_config.r,\n            lora_alpha=lora_config.lora_alpha,\n            lora_dropout=lora_config.lora_dropout,\n            target_modules=lora_config.target_modules,\n            bias=lora_config.bias,\n        )\n\n        model = get_peft_model(model, lora_cfg)\n        model.print_trainable_parameters()\n\n    # For now, do *not* enable gradient checkpointing (to keep things simpler)\n    return model, tokenizer\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:56:16.912940Z","iopub.execute_input":"2025-12-03T10:56:16.913203Z","iopub.status.idle":"2025-12-03T10:56:16.919246Z","shell.execute_reply.started":"2025-12-03T10:56:16.913180Z","shell.execute_reply":"2025-12-03T10:56:16.918542Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# ============================\n# 4. Metrics (incl. safety_f1)\n# ============================\n\ndef compute_metrics(eval_pred) -> Dict[str, float]:\n    predictions, labels = eval_pred\n    if isinstance(predictions, tuple):\n        predictions = predictions[0]\n\n    preds = np.argmax(predictions, axis=1)\n\n    accuracy = accuracy_score(labels, preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        labels, preds, average=None, zero_division=0\n    )\n\n    macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n        labels, preds, average=\"macro\", zero_division=0\n    )\n\n    # Financial safety subset\n    safety_mask = np.isin(labels, FIN_SAFETY_LABEL_IDS)\n    if safety_mask.sum() > 0:\n        safety_true = labels[safety_mask]\n        safety_pred = preds[safety_mask]\n        safety_f1 = precision_recall_fscore_support(\n            safety_true, safety_pred, average=\"macro\", zero_division=0\n        )[2]\n    else:\n        safety_f1 = 0.0\n\n    metrics = {\n        \"accuracy\": float(accuracy),\n        \"macro_precision\": float(macro_p),\n        \"macro_recall\": float(macro_r),\n        \"macro_f1\": float(macro_f1),\n        \"safety_f1\": float(safety_f1),\n    }\n\n    # Per-label F1 for the 6 financial labels\n    for lbl_id in FIN_SAFETY_LABEL_IDS:\n        name = ID2LABEL[lbl_id]\n        metrics[f\"f1_{name}\"] = float(f1[lbl_id]) if lbl_id < len(f1) else 0.0\n\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:56:17.871448Z","iopub.execute_input":"2025-12-03T10:56:17.872021Z","iopub.status.idle":"2025-12-03T10:56:17.878321Z","shell.execute_reply.started":"2025-12-03T10:56:17.871998Z","shell.execute_reply":"2025-12-03T10:56:17.877537Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# ============================\n# 5. Training function\n# ============================\n\ndef train(\n    model_config: ModelConfig,\n    lora_config: LoRAConfig,\n    train_config: TrainConfig,\n    data_config: DataConfig,\n    use_wandb: bool = False,\n):\n    \"\"\"Main training function.\"\"\"\n\n    set_seed(train_config.seed)\n\n    # 1. Model + tokenizer\n    model, tokenizer = setup_model_and_tokenizer(model_config, lora_config)\n\n    # 2. Datasets\n    datasets = prepare_datasets(data_config, tokenizer, model_config.max_length)\n    assert \"train\" in datasets and \"validation\" in datasets, \"Train/validation splits missing!\"\n\n    # 3. HF eval/save step multiple fix\n    eval_steps = train_config.eval_steps\n    save_steps = train_config.save_steps\n    if save_steps % eval_steps != 0:\n        logger.warning(\n            f\"save_steps={save_steps} is not a multiple of eval_steps={eval_steps}. \"\n            f\"Overriding save_steps to {eval_steps} to satisfy HF constraint.\"\n        )\n        save_steps = eval_steps\n\n    training_args = TrainingArguments(\n        output_dir=train_config.output_dir,\n        num_train_epochs=train_config.num_epochs,\n        per_device_train_batch_size=train_config.batch_size,\n        per_device_eval_batch_size=train_config.batch_size * 2,\n        gradient_accumulation_steps=train_config.gradient_accumulation_steps,\n        learning_rate=train_config.learning_rate,\n        warmup_ratio=train_config.warmup_ratio,\n        weight_decay=train_config.weight_decay,\n        max_grad_norm=train_config.max_grad_norm,\n\n        fp16=train_config.fp16,     # False => pure fp32, no GradScaler weirdness\n        logging_steps=train_config.logging_steps,\n\n        eval_strategy=\"steps\",\n        eval_steps=eval_steps,\n        save_strategy=\"steps\",\n        save_steps=save_steps,\n\n        load_best_model_at_end=True,\n        metric_for_best_model=\"safety_f1\",\n        greater_is_better=True,\n\n        report_to=\"none\",\n        seed=train_config.seed,\n        remove_unused_columns=False,\n\n        # Tell Trainer that our label field is 'labels'\n        label_names=[\"labels\"],\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=datasets[\"train\"],\n        eval_dataset=datasets[\"validation\"],\n        compute_metrics=compute_metrics,\n        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n    )\n\n    # Optional sanity check BEFORE training\n    logger.info(\"Running one sanity-check forward pass...\")\n    from torch.utils.data import DataLoader\n    train_dl = DataLoader(datasets[\"train\"], batch_size=2, shuffle=True)\n    batch = next(iter(train_dl))\n    batch = {k: v.to(model.device) for k, v in batch.items()}\n    with torch.no_grad():\n        out = model(**batch)\n    logger.info(f\"[Sanity] loss={float(out.loss):.4f}, logits_shape={tuple(out.logits.shape)}\")\n\n    # 4. Train\n    logger.info(\"Starting training...\")\n    train_result = trainer.train()\n\n    logger.info(\"Saving final model...\")\n    trainer.save_model(f\"{train_config.output_dir}/final\")\n    tokenizer.save_pretrained(f\"{train_config.output_dir}/final\")\n\n    with open(f\"{train_config.output_dir}/train_metrics.json\", \"w\") as f:\n        json.dump(train_result.metrics, f, indent=2)\n\n    # 5. Test evaluation\n    if \"test\" in datasets:\n        logger.info(\"Evaluating on test set...\")\n        test_results = trainer.evaluate(datasets[\"test\"])\n        with open(f\"{train_config.output_dir}/test_metrics.json\", \"w\") as f:\n            json.dump(test_results, f, indent=2)\n        logger.info(f\"Test Results: {test_results}\")\n\n    return trainer, model, tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:56:18.524044Z","iopub.execute_input":"2025-12-03T10:56:18.524310Z","iopub.status.idle":"2025-12-03T10:56:18.535791Z","shell.execute_reply.started":"2025-12-03T10:56:18.524291Z","shell.execute_reply":"2025-12-03T10:56:18.534985Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from datasets import load_dataset\nimport json\n\nwith open(\"/kaggle/input/llamaguard-ft-dataset/train.json\") as f:\n    tmp = json.load(f)\nprint(tmp[0].keys())\n# should include: 'text', 'label', 'policy_label', 'tags', 'adversarial_flag', 'metadata', 'explanation'\n\n# After prepare_datasets:\n# 1. Build model + tokenizer (reuses your setup function)\nmodel_dbg, tokenizer_dbg = setup_model_and_tokenizer(model_cfg, lora_cfg)\n\n# 2. Prepare datasets\ndatasets_dbg = prepare_datasets(data_cfg, tokenizer_dbg, model_cfg.max_length)\nprint(datasets_dbg[\"train\"].column_names)\n# -> should show: ['input_ids', 'attention_mask', 'labels']\n\n# should include: 'input_ids', 'attention_mask', 'labels'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:56:19.193845Z","iopub.execute_input":"2025-12-03T10:56:19.194609Z","iopub.status.idle":"2025-12-03T10:56:35.036920Z","shell.execute_reply.started":"2025-12-03T10:56:19.194582Z","shell.execute_reply":"2025-12-03T10:56:35.036099Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['id', 'text', 'label', 'policy_label', 'tags', 'adversarial_flag', 'metadata', 'explanation'])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/53.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bdc13a13a9848469591d46e69a181ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b6fb46c7f73498b9cae78d15f5a6115"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c895ac086558427690fb529c09b1dd4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6a8fc45ecfa4f74b6e7afe021f2ac9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83c5db807256412eabb26eb4f7c8e07f"}},"metadata":{}},{"name":"stderr","text":"Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-Guard-3-1B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 11,325,440 || all params: 1,247,193,088 || trainable%: 0.9081\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2089 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0d70cddd7a34f4fa21355fbe621628b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/231 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dda01ebb31a64dcfb6f41c2aee802e8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/267 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f49ab2b9ca1d4ddd909c5a4a9dc83d24"}},"metadata":{}},{"name":"stdout","text":"['input_ids', 'attention_mask', 'labels']\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# 1) Confirm labels & mapping\nimport collections, json\n\nwith open(\"/kaggle/input/llamaguard-ft-dataset/train.json\") as f:\n    train_raw = json.load(f)\n\nlabel_counts = collections.Counter(ex[\"label\"] for ex in train_raw)\nprint(\"Num train examples:\", len(train_raw))\nprint(\"Num unique labels:\", len(label_counts))\nprint(\"Labels present:\", label_counts)\nprint(\"Labels in dataset but not in LABEL2ID:\",\n      set(label_counts.keys()) - set(LABEL2ID.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:56:35.038211Z","iopub.execute_input":"2025-12-03T10:56:35.038566Z","iopub.status.idle":"2025-12-03T10:56:35.054843Z","shell.execute_reply.started":"2025-12-03T10:56:35.038531Z","shell.execute_reply":"2025-12-03T10:56:35.053961Z"}},"outputs":[{"name":"stdout","text":"Num train examples: 2089\nNum unique labels: 26\nLabels present: Counter({'illicit_market_manipulation': 233, 'safe_info': 191, 'illicit_money_laundering': 179, 'safe_with_disclaimer': 175, 'high_value_approval': 163, 'illicit_regulatory_evasion': 163, 'redirect_to_docs': 136, 'redirect_to_professional': 119, 'illicit_insider_trading': 101, 'ambiguous_needs_review': 99, 'code_interpreter_abuse': 93, 'illicit_fraud': 92, 'violent_crime': 68, 'hate_speech': 48, 'specialized_advice': 37, 'defamation': 28, 'illicit_unauthorized_advice': 28, 'privacy_violation': 22, 'weapons': 21, 'child_sexual_exploitation': 18, 'sexual_content': 18, 'ip_violation': 18, 'elections': 14, 'sex_related_crime': 9, 'non_violent_crime': 8, 'suicide_self_harm': 8})\nLabels in dataset but not in LABEL2ID: set()\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# 2) Check HF dataset columns\nmodel, tokenizer = setup_model_and_tokenizer(model_cfg, lora_cfg)\ndatasets = prepare_datasets(data_cfg, tokenizer, model_cfg.max_length)\nprint(datasets[\"train\"].column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:56:35.055435Z","iopub.execute_input":"2025-12-03T10:56:35.055627Z","iopub.status.idle":"2025-12-03T10:56:44.907916Z","shell.execute_reply.started":"2025-12-03T10:56:35.055612Z","shell.execute_reply":"2025-12-03T10:56:44.907123Z"}},"outputs":[{"name":"stderr","text":"Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-Guard-3-1B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 11,325,440 || all params: 1,247,193,088 || trainable%: 0.9081\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2089 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78cd9911c4b64d5da508eaf44ca15a44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/231 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a37f3cfc649543129abeb55c57b1a203"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/267 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b99d28d5190e42af802de2c88421513a"}},"metadata":{}},{"name":"stdout","text":"['input_ids', 'attention_mask', 'labels']\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Quick numeric sanity: run 1 batch and compute loss manually\nfrom torch.utils.data import DataLoader\n\ndatasets = prepare_datasets(data_cfg, tokenizer, model_cfg.max_length)\ntrain_dl = DataLoader(datasets[\"train\"], batch_size=2)\n\nbatch = next(iter(train_dl))\nbatch = {k: v.to(model.device) for k, v in batch.items()}\n\nwith torch.no_grad():\n    out = model(**batch)\n    print(\"Initial loss:\", out.loss.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:56:44.909102Z","iopub.execute_input":"2025-12-03T10:56:44.909285Z","iopub.status.idle":"2025-12-03T10:56:47.307532Z","shell.execute_reply.started":"2025-12-03T10:56:44.909271Z","shell.execute_reply":"2025-12-03T10:56:47.306869Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2089 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19f4a1bfa9074da08a0130ab1e85599f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/231 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76ac50a665364720810751c28196d2bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/267 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd528f77d3564a348b6ee829bb4a12f8"}},"metadata":{}},{"name":"stdout","text":"Initial loss: 2.844724416732788\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"\n\n# ============================\n# 6. Start button\n# ============================\n\nmodel_cfg = ModelConfig(\n    base_model=\"meta-llama/Llama-Guard-3-1B\",\n    num_labels=NUM_LABELS,\n    max_length=512,\n)\n\nlora_cfg = LoRAConfig(\n    enabled=True,\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n)\n\ntrain_cfg = TrainConfig(\n    output_dir=\"/kaggle/working/financial-guardrails\",\n    num_epochs=5,\n    batch_size=4,\n)\n\ndata_cfg = DataConfig(\n    base_dir=\"/kaggle/input/llamaguard-ft-dataset\"\n)\n\ntrainer, model, tokenizer = train(\n    model_config=model_cfg,\n    lora_config=lora_cfg,\n    train_config=train_cfg,\n    data_config=data_cfg,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:56:47.308387Z","iopub.execute_input":"2025-12-03T10:56:47.308741Z","iopub.status.idle":"2025-12-03T13:02:31.286763Z","shell.execute_reply.started":"2025-12-03T10:56:47.308716Z","shell.execute_reply":"2025-12-03T13:02:31.286085Z"}},"outputs":[{"name":"stderr","text":"Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-Guard-3-1B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 11,325,440 || all params: 1,247,193,088 || trainable%: 0.9081\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2089 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ef1ad17615d4920a97cf31dfeeeaaea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/231 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"629668dfc41342c4bcf1543bc9b687a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/267 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c73c7dff4fd4c5d9b90df96e0df71ef"}},"metadata":{}},{"name":"stderr","text":"WARNING:__main__:save_steps=500 is not a multiple of eval_steps=200. Overriding save_steps to 200 to satisfy HF constraint.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='655' max='655' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [655/655 2:04:01, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Macro Precision</th>\n      <th>Macro Recall</th>\n      <th>Macro F1</th>\n      <th>Safety F1</th>\n      <th>F1 Illicit Market Manipulation</th>\n      <th>F1 Illicit Insider Trading</th>\n      <th>F1 Illicit Money Laundering</th>\n      <th>F1 Illicit Fraud</th>\n      <th>F1 Illicit Regulatory Evasion</th>\n      <th>F1 Illicit Unauthorized Advice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>0.145500</td>\n      <td>0.011064</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.015900</td>\n      <td>0.016680</td>\n      <td>0.995671</td>\n      <td>0.998264</td>\n      <td>0.997024</td>\n      <td>0.997570</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.006600</td>\n      <td>0.019443</td>\n      <td>0.995671</td>\n      <td>0.998106</td>\n      <td>0.997024</td>\n      <td>0.997488</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [34/34 01:24]\n    </div>\n    "},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"import json, os\n\nbase = \"/kaggle/working/financial-guardrails\"\n\nwith open(os.path.join(base, \"train_metrics.json\")) as f:\n    train_metrics = json.load(f)\n\nwith open(os.path.join(base, \"test_metrics.json\")) as f:\n    test_metrics = json.load(f)\n\nprint(\"Train metrics:\", train_metrics)\nprint(\"\\nTest metrics:\", test_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T13:45:33.038657Z","iopub.execute_input":"2025-12-03T13:45:33.039174Z","iopub.status.idle":"2025-12-03T13:45:33.044959Z","shell.execute_reply.started":"2025-12-03T13:45:33.039152Z","shell.execute_reply":"2025-12-03T13:45:33.044346Z"}},"outputs":[{"name":"stdout","text":"Train metrics: {'train_runtime': 7450.5524, 'train_samples_per_second': 1.402, 'train_steps_per_second': 0.088, 'total_flos': 3.1590486638592e+16, 'train_loss': 0.3119972374494621, 'epoch': 5.0}\n\nTest metrics: {'eval_loss': 0.022920673713088036, 'eval_accuracy': 0.9925093632958801, 'eval_macro_precision': 0.9960653157584104, 'eval_macro_recall': 0.9967892976588628, 'eval_macro_f1': 0.9963773286754652, 'eval_safety_f1': 1.0, 'eval_f1_illicit_market_manipulation': 1.0, 'eval_f1_illicit_insider_trading': 1.0, 'eval_f1_illicit_money_laundering': 1.0, 'eval_f1_illicit_fraud': 1.0, 'eval_f1_illicit_regulatory_evasion': 1.0, 'eval_f1_illicit_unauthorized_advice': 1.0, 'eval_runtime': 86.7525, 'eval_samples_per_second': 3.078, 'eval_steps_per_second': 0.392, 'epoch': 5.0}\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# ============================\n# 7. Manual interactive sanity check\n# ============================\nimport time\nimport torch\nimport torch.nn.functional as F\n\n# Make sure we're in eval mode\nmodel.eval()\n\n# Figure out which device the model is on\ndevice = next(model.parameters()).device\nprint(f\"\\nModel is on device: {device}\")\nprint(\"Type a query to test the guardrail classifier. Type 'q' or 'quit' to exit.\\n\")\n\ndef classify_guardrail(text: str):\n    \"\"\"Run a single query through the fine-tuned Llama-Guard classifier.\"\"\"\n    enc = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=True,\n        max_length=model_cfg.max_length,\n    )\n    enc = {k: v.to(device) for k, v in enc.items()}\n\n    with torch.no_grad():\n        outputs = model(**enc)\n        logits = outputs.logits\n        probs = F.softmax(logits, dim=-1)[0]  # (num_labels,)\n\n    pred_id = int(probs.argmax().item())\n    pred_label = ID2LABEL[pred_id]\n    confidence = float(probs[pred_id].item())\n\n    return pred_label, confidence, probs.cpu().tolist()\n\n# Optional: helper to pretty-print top-k labels\ndef print_top_k(probs_list, k: int = 5):\n    probs_tensor = torch.tensor(probs_list)\n    top_vals, top_idx = torch.topk(probs_tensor, k)\n    print(\"\\nTop classes:\")\n    for val, idx in zip(top_vals, top_idx):\n        lbl = ID2LABEL[int(idx)]\n        print(f\"  {lbl:30s} : {float(val):.4f}\")\n\n# Interactive loop\nwhile True:\n    q = input(\"\\nEnter a query (or 'q' to quit): \").strip()\n    if q.lower() in {\"q\", \"quit\", \"exit\"}:\n        print(\"Exiting manual check loop.\")\n        break\n    if not q:\n        print(\"Empty query, try again.\")\n        continue\n\n    t0 = time.time()\n    label, conf, probs_list = classify_guardrail(q)\n    dt = (time.time() - t0) * 1000.0\n\n    print(f\"\\nPredicted label : {label}\")\n    print(f\"Confidence      : {conf:.3f}\")\n    print(f\"Latency         : {dt:.1f} ms\")\n\n    # Show top-5 labels for debugging / intuition\n    print_top_k(probs_list, k=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T14:04:32.085437Z","iopub.execute_input":"2025-12-03T14:04:32.085734Z","iopub.status.idle":"2025-12-03T14:14:11.045798Z","shell.execute_reply.started":"2025-12-03T14:04:32.085711Z","shell.execute_reply":"2025-12-03T14:14:11.045120Z"}},"outputs":[{"name":"stdout","text":"\nModel is on device: cuda:0\nType a query to test the guardrail classifier. Type 'q' or 'quit' to exit.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  insider trading\n"},{"name":"stdout","text":"\nPredicted label : illicit_insider_trading\nConfidence      : 0.442\nLatency         : 44.7 ms\n\nTop classes:\n  illicit_insider_trading        : 0.4416\n  redirect_to_docs               : 0.1791\n  weapons                        : 0.0622\n  safe_info                      : 0.0530\n  child_sexual_exploitation      : 0.0522\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  should i invest in a nearby tea shop \n"},{"name":"stdout","text":"\nPredicted label : redirect_to_docs\nConfidence      : 0.256\nLatency         : 54.9 ms\n\nTop classes:\n  redirect_to_docs               : 0.2563\n  weapons                        : 0.1891\n  ambiguous_needs_review         : 0.1140\n  sexual_content                 : 0.1139\n  illicit_insider_trading        : 0.0720\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  jdsfjdkgdsk\n"},{"name":"stdout","text":"\nPredicted label : safe_info\nConfidence      : 0.239\nLatency         : 54.6 ms\n\nTop classes:\n  safe_info                      : 0.2387\n  privacy_violation              : 0.1292\n  specialized_advice             : 0.1266\n  ip_violation                   : 0.0683\n  hate_speech                    : 0.0682\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  aryan jain\n"},{"name":"stdout","text":"\nPredicted label : safe_info\nConfidence      : 0.684\nLatency         : 49.8 ms\n\nTop classes:\n  safe_info                      : 0.6839\n  suicide_self_harm              : 0.1829\n  weapons                        : 0.0725\n  illicit_market_manipulation    : 0.0154\n  ambiguous_needs_review         : 0.0080\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  aryan\n"},{"name":"stdout","text":"\nPredicted label : safe_info\nConfidence      : 0.717\nLatency         : 46.4 ms\n\nTop classes:\n  safe_info                      : 0.7165\n  weapons                        : 0.0613\n  suicide_self_harm              : 0.0391\n  sexual_content                 : 0.0321\n  violent_crime                  : 0.0285\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  aryan fuck you\n"},{"name":"stdout","text":"\nPredicted label : ambiguous_needs_review\nConfidence      : 0.309\nLatency         : 49.3 ms\n\nTop classes:\n  ambiguous_needs_review         : 0.3086\n  weapons                        : 0.1318\n  safe_info                      : 0.1181\n  hate_speech                    : 0.0953\n  sexual_content                 : 0.0895\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  bitch\n"},{"name":"stdout","text":"\nPredicted label : safe_info\nConfidence      : 0.436\nLatency         : 46.5 ms\n\nTop classes:\n  safe_info                      : 0.4362\n  suicide_self_harm              : 0.2092\n  sexual_content                 : 0.1710\n  weapons                        : 0.0477\n  ambiguous_needs_review         : 0.0419\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  shut up\n"},{"name":"stdout","text":"\nPredicted label : sexual_content\nConfidence      : 0.213\nLatency         : 44.3 ms\n\nTop classes:\n  sexual_content                 : 0.2130\n  weapons                        : 0.1625\n  safe_info                      : 0.1315\n  specialized_advice             : 0.0960\n  ambiguous_needs_review         : 0.0765\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  son of a bitch\n"},{"name":"stdout","text":"\nPredicted label : suicide_self_harm\nConfidence      : 0.280\nLatency         : 50.8 ms\n\nTop classes:\n  suicide_self_harm              : 0.2798\n  safe_info                      : 0.1855\n  ambiguous_needs_review         : 0.1712\n  hate_speech                    : 0.1012\n  weapons                        : 0.0492\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  finance mafia\n"},{"name":"stdout","text":"\nPredicted label : safe_info\nConfidence      : 0.410\nLatency         : 47.0 ms\n\nTop classes:\n  safe_info                      : 0.4095\n  suicide_self_harm              : 0.1214\n  ip_violation                   : 0.0853\n  illicit_money_laundering       : 0.0805\n  sexual_content                 : 0.0650\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  how to start a mafia\n"},{"name":"stdout","text":"\nPredicted label : redirect_to_professional\nConfidence      : 0.198\nLatency         : 53.6 ms\n\nTop classes:\n  redirect_to_professional       : 0.1979\n  suicide_self_harm              : 0.1927\n  hate_speech                    : 0.1251\n  safe_info                      : 0.1003\n  sexual_content                 : 0.0771\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  mafia\n"},{"name":"stdout","text":"\nPredicted label : safe_info\nConfidence      : 0.266\nLatency         : 46.3 ms\n\nTop classes:\n  safe_info                      : 0.2660\n  weapons                        : 0.2103\n  ip_violation                   : 0.1526\n  sexual_content                 : 0.1392\n  ambiguous_needs_review         : 0.0516\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  mafia start\n"},{"name":"stdout","text":"\nPredicted label : sexual_content\nConfidence      : 0.204\nLatency         : 44.3 ms\n\nTop classes:\n  sexual_content                 : 0.2037\n  suicide_self_harm              : 0.1651\n  safe_info                      : 0.1472\n  ambiguous_needs_review         : 0.0967\n  hate_speech                    : 0.0812\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  bomb\n"},{"name":"stdout","text":"\nPredicted label : sexual_content\nConfidence      : 0.574\nLatency         : 40.0 ms\n\nTop classes:\n  sexual_content                 : 0.5745\n  weapons                        : 0.1581\n  privacy_violation              : 0.0572\n  ambiguous_needs_review         : 0.0541\n  suicide_self_harm              : 0.0428\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  aryan bomb\n"},{"name":"stdout","text":"\nPredicted label : weapons\nConfidence      : 0.371\nLatency         : 44.2 ms\n\nTop classes:\n  weapons                        : 0.3712\n  ambiguous_needs_review         : 0.1332\n  sexual_content                 : 0.1003\n  privacy_violation              : 0.0917\n  safe_info                      : 0.0832\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  nigga\n"},{"name":"stdout","text":"\nPredicted label : safe_info\nConfidence      : 0.307\nLatency         : 44.4 ms\n\nTop classes:\n  safe_info                      : 0.3074\n  ambiguous_needs_review         : 0.2831\n  suicide_self_harm              : 0.1112\n  sexual_content                 : 0.0972\n  weapons                        : 0.0554\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query (or 'q' to quit):  q\n"},{"name":"stdout","text":"Exiting manual check loop.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Use a pipeline as a high-level helper\nfrom transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-Guard-3-1B\")\nmessages = [\n    {\"role\": \"user\", \"content\": \"what do a aryan eat for jain\"},\n]\npipe(messages)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T14:16:14.167053Z","iopub.execute_input":"2025-12-03T14:16:14.167670Z","iopub.status.idle":"2025-12-03T14:16:16.282659Z","shell.execute_reply.started":"2025-12-03T14:16:14.167645Z","shell.execute_reply":"2025-12-03T14:16:16.281902Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': [{'role': 'user',\n    'content': 'what do a aryan eat for jain'},\n   {'role': 'assistant', 'content': '\\n\\nsafe'}]}]"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}